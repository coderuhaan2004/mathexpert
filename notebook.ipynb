{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e75f545",
   "metadata": {},
   "source": [
    "## Topic: AI in Personalized Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bea82c",
   "metadata": {},
   "source": [
    "## IIT Ropar Minor in AI Project: Mathexpert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f5183d",
   "metadata": {},
   "source": [
    "## Project Architecture:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed50db",
   "metadata": {},
   "source": [
    "![Project Architecture](data/Manim%20Project%20Architecture.png \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513aff3a",
   "metadata": {},
   "source": [
    "### Datasets used\n",
    "1. [Hugging Face Dataset] brando/olympiad-bench-imo-math-boxed-825-v2-21-08-2024 (For Math Olympiad problems)\n",
    "2. [Hugging Face Dataset] nvidia/OpenMathReasoning (for calculus problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bc9f05",
   "metadata": {},
   "source": [
    "## Tech stack\n",
    "1. Chroma DB (vector database for context retrieval)\n",
    "2. BeautifulSoup4 (for web scrapping entire documentation of Manim)\n",
    "3. Manim (python library for elegant animations)\n",
    "4. Streamlit (for web app development)\n",
    "5. Sqlite3 (database for Math problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7512fe3b",
   "metadata": {},
   "source": [
    "### Make sure to install the python libraries from requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a642e",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5397708c",
   "metadata": {},
   "source": [
    "## First lets setup the video animation generation (manim) part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ec580c",
   "metadata": {},
   "source": [
    "### script_generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234021e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "from typing import Any, Dict\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_KEY\")\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "def extract_json_dict(s: str) -> Dict[str, Any]:\n",
    "    # Try to find a ```json ... ``` fenced block (or ``` ... ```)\n",
    "    m = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", s, flags=re.DOTALL)\n",
    "    if m:\n",
    "        json_text = m.group(1)\n",
    "    else:\n",
    "        # Fallback: maybe the whole string is JSON\n",
    "        json_text = s.strip()\n",
    "\n",
    "    # Parse into dict\n",
    "    obj = json.loads(json_text)\n",
    "\n",
    "    if not isinstance(obj, dict):\n",
    "        raise ValueError(\"Extracted JSON is not an object/dictionary\")\n",
    "    return obj\n",
    "\n",
    "def generate_script_json(USER_PROMPT):\n",
    "    entire_prompt = \"\"\"\n",
    "    You are an expert animation director and Manim engineer.\n",
    "    Your job is to convert the user's request into a retrieval-optimized JSON script for generating a Manim animation.\n",
    "    \n",
    "    You MUST:\n",
    "    - Output ONLY valid JSON (no markdown, no comments, no trailing commas).\n",
    "    - Keep the plan executable: each scene should be concrete and animatable.\n",
    "    - Optimize for retrieval from a documentation RAG system (Chroma) that stores Manim docs as:\n",
    "      (1) section chunks (explanations),\n",
    "      (2) code chunks (code blocks + nearby context),\n",
    "      (3) optional symbol chunks (class/function names and signatures).\n",
    "    \n",
    "    CRITICAL RETRIEVAL REQUIREMENTS:\n",
    "    - Every action MUST contain retrieval fields that make it easy to fetch correct docs/code:\n",
    "      - exact_symbols: list of likely Manim class/function names (CamelCase or dotted paths if known)\n",
    "      - semantic_queries: short natural-language queries for vector search\n",
    "      - keyword_tags: concise tags (1–3 words) to help reranking and filtering\n",
    "      - expected_doc_areas: likely doc areas to search (reference/tutorials/examples/guides)\n",
    "      - unknown_api_intent: if you are not sure which Manim symbol(s) to use, set this to true and provide strong fallback keywords (see below)\n",
    "    \n",
    "    UNKNOWN API / FALLBACK KEYWORDS (IMPORTANT):\n",
    "    - If you do NOT know the exact Manim class/function to call for an action:\n",
    "      - Set \"unknown_api_intent\": true\n",
    "      - Put your best guesses (even if unsure) in exact_symbols\n",
    "      - Add at least 3–6 targeted \"keyword_tags\" chosen from this controlled list:\n",
    "        [\"camera move\",\"zoom\",\"pan\",\"follow\",\"3D\",\"axes\",\"graph\",\"plot\",\"function graph\",\"parametric curve\",\n",
    "         \"vector field\",\"number line\",\"geometry\",\"shapes\",\"transform\",\"morph\",\"highlight\",\"surround\",\"brace\",\n",
    "         \"label\",\"text\",\"mathtex\",\"latex\",\"align\",\"arrange\",\"vgroup\",\"layout\",\"fade\",\"write\",\"create\",\n",
    "         \"timing\",\"laggedstart\",\"animationgroup\",\"updater\",\"always_redraw\",\"valuetracker\",\"tracker\",\n",
    "         \"color gradient\",\"stroke\",\"fill\",\"opacity\",\"path\",\"traced path\",\"motion path\",\"rotate\",\"scale\",\n",
    "         \"shift\",\"move to\",\"background\",\"grid\",\"numberplane\",\"coordinate system\",\"table\",\"matrix\",\n",
    "         \"code example\",\"best practice\",\"performance\",\"renderer\",\"cairo\",\"opengl\"]\n",
    "      - Add at least 2–4 \"semantic_queries\" explicitly phrased to discover the right API, e.g.:\n",
    "        \"manim how to do <intent> which class/function\"\n",
    "        \"manim <intent> example code\"\n",
    "        \"manim reference <intent> camera/mobject/animation\"\n",
    "      - In \"constraints\", describe the intent precisely (what should happen visually), so retrieval can match.\n",
    "    \n",
    "    ACCURACY RULES:\n",
    "    - Do not invent APIs. If unsure, mark unknown_api_intent true and use fallback keywords.\n",
    "    - Prefer smaller scenes (15–40 seconds each) but adapt to user needs.\n",
    "    - Ensure smooth continuity: each scene must specify transition_to_next.\n",
    "    - Prefer efficient primitives and avoid heavy compute when possible.\n",
    "    \n",
    "    JSON schema (must match exactly):\n",
    "         {\n",
    "          \"title\": \"string\",\n",
    "          \"audience\": \"beginner|intermediate|advanced\",\n",
    "          \"target_duration_seconds\": 0,\n",
    "          \"style\": {\n",
    "            \"aspect_ratio\": \"16:9|9:16|1:1\",\n",
    "            \"pacing\": \"slow|medium|fast\",\n",
    "            \"tone\": \"string\"\n",
    "          },\n",
    "          \"constraints\": {\n",
    "            \"render_quality\": \"low|medium|high\",\n",
    "            \"avoid_heavy_compute\": true,\n",
    "            \"math_typesetting\": true\n",
    "          },\n",
    "          \"scenes\": [\n",
    "            {\n",
    "              \"id\": \"string\",\n",
    "              \"duration_seconds\": 0,\n",
    "              \"goal\": \"string\",\n",
    "              \"voiceover\": \"string\",\n",
    "              \"on_screen_text\": [\"string\"],\n",
    "              \"actions\": [\n",
    "                {\n",
    "                  \"id\": \"string\",\n",
    "                  \"description\": \"string\",\n",
    "                  \"code_intent\": \"string\",\n",
    "                  \"retrieval\": {\n",
    "                    \"unknown_api_intent\": true,\n",
    "                    \"exact_symbols\": [\"string\"],\n",
    "                    \"queries\": [\"string\"],\n",
    "                    \"tags\": [\"string\"],\n",
    "                    \"doc_area_hints\": [\"reference|tutorial|examples|guides\"]\n",
    "                  }\n",
    "                }\n",
    "              ],\n",
    "              \"transition_to_next\": {\n",
    "                \"type\": \"cut|fade|transform|camera_move|wipe\",\n",
    "                \"description\": \"string\"\n",
    "              }\n",
    "            }\n",
    "          ],\n",
    "          \"retrieval_plan\": {\n",
    "            \"collections\": {\n",
    "              \"sections\": \"string\",\n",
    "              \"code\": \"string\",\n",
    "              \"symbols\": \"string\"\n",
    "            },\n",
    "            \"top_k\": {\n",
    "              \"sections\": 0,\n",
    "              \"code\": 0,\n",
    "              \"symbols\": 0\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    \n",
    "    Guidance for exact_symbols (use if relevant, otherwise guesses + unknown_api_intent true):\n",
    "    - Scenes/camera: Scene, MovingCameraScene, ThreeDScene, ZoomedScene\n",
    "    - Text/math: Text, MarkupText, Tex, MathTex\n",
    "    - Geometry/mobjects: VGroup, Group, Dot, Line, Arrow, Circle, Square, Rectangle, Polygon, Brace\n",
    "    - Coordinate systems: Axes, NumberPlane\n",
    "    - Animations: Create, Write, FadeIn, FadeOut, Transform, ReplacementTransform, AnimationGroup, Succession, LaggedStart, Indicate, Circumscribe\n",
    "    - Dynamics: ValueTracker, always_redraw, Updater\n",
    "    - Motion: Rotate, Scale, Shift, MoveTo (as method intent)\n",
    "    \n",
    "    expected_doc_areas must be chosen only from:\n",
    "    [\"reference/scene\",\"reference/mobject\",\"reference/animation\",\"reference/camera\",\"reference/utils\",\"tutorials\",\"examples\",\"guides\"]\n",
    "    \n",
    "    Now, take the user's request below and produce the JSON script.\n",
    "    \n",
    "    USER REQUEST: \n",
    "\n",
    "    \"\"\"\n",
    "    sys_user_prompt = entire_prompt + USER_PROMPT\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-3-flash-preview\",\n",
    "        contents=sys_user_prompt,\n",
    "    )\n",
    "    return extract_json_dict(response.text)\n",
    "\n",
    "# if __name__ ==\"__main__\":\n",
    "#     USER_PROMPT = \"\"\"\n",
    "#     Create a 60–75 second Manim animation (16:9) that teaches the concept of a derivative as “slope of the tangent line”.\n",
    "    \n",
    "#     Requirements:\n",
    "#     1) Scene 1 (intro): Show the function f(x) = x^2 on axes. Put the title text “Derivative = slope of tangent” at the top.\n",
    "#     2) Scene 2 (secant → tangent): Pick two points on the parabola at x=1 and x=1+h. Draw the secant line between them. Display the slope formula:\n",
    "#        (f(1+h) - f(1)) / h\n",
    "#        Animate h shrinking toward 0 and smoothly morph the secant line into the tangent line at x=1.\n",
    "#     3) Scene 3 (result): Show the derivative of x^2 is 2x and evaluate at x=1 to get slope 2. Visually show the tangent line has slope 2 (a small “rise over run” marker is enough).\n",
    "#     4) Use clean labels (MathTex). Keep it efficient: avoid heavy particle effects or complex 3D.\n",
    "#     5) Include smooth transitions between scenes, and keep the narration concise (1–2 sentences per scene).\n",
    "#     \"\"\"\n",
    "#     print(generate_script_json(USER_PROMPT=USER_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe84a10e",
   "metadata": {},
   "source": [
    "### retrieve_context.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aff4a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Manim Animation Script Context Retriever\n",
    "Efficiently retrieves relevant documentation from ChromaDB based on animation script JSON\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import chromadb\n",
    "from typing import Dict, List, Any, Optional, Set\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RetrievalResult:\n",
    "    \"\"\"Structured result from ChromaDB query\"\"\"\n",
    "    chunk_id: str\n",
    "    text: str\n",
    "    distance: float\n",
    "    class_name: str\n",
    "    qualified_name: str\n",
    "    category: str\n",
    "    chunk_type: str\n",
    "    url: str\n",
    "    source_query: str  # Which query generated this result\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.chunk_id)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, RetrievalResult):\n",
    "            return self.chunk_id == other.chunk_id\n",
    "        return False\n",
    "\n",
    "\n",
    "class ManimContextRetriever:\n",
    "    \"\"\"\n",
    "    Retrieves relevant Manim documentation context based on animation script JSON.\n",
    "    Uses intelligent query generation and deduplication for efficient retrieval.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: str = \"./manim_chromadb\", \n",
    "                 collection_name: str = \"manim_docs\"):\n",
    "        \"\"\"\n",
    "        Initialize the retriever\n",
    "        \n",
    "        Args:\n",
    "            db_path: Path to ChromaDB storage\n",
    "            collection_name: Name of the collection to query\n",
    "        \"\"\"\n",
    "        self.db_path = db_path\n",
    "        self.collection_name = collection_name\n",
    "        \n",
    "        # Initialize ChromaDB client\n",
    "        self.client = chromadb.PersistentClient(path=db_path)\n",
    "        self.collection = self.client.get_collection(name=collection_name)\n",
    "        \n",
    "        print(f\"Connected to ChromaDB collection: {collection_name}\")\n",
    "        print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "    \n",
    "    def retrieve_for_script(self, script_json: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Main retrieval function that processes entire animation script\n",
    "        \n",
    "        Args:\n",
    "            script_json: Animation script in the specified JSON format\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing organized retrieval results\n",
    "        \"\"\"\n",
    "        # Get retrieval configuration\n",
    "        retrieval_plan = script_json.get('retrieval_plan', {})\n",
    "        top_k = retrieval_plan.get('top_k', {})\n",
    "        \n",
    "        # Default top_k values if not specified\n",
    "        default_top_k = {\n",
    "            'sections': top_k.get('sections', 3),\n",
    "            'code': top_k.get('code', 5),\n",
    "            'symbols': top_k.get('symbols', 3)\n",
    "        }\n",
    "        \n",
    "        # Collect all retrieval requests\n",
    "        all_queries = self._extract_all_queries(script_json)\n",
    "        \n",
    "        # Execute queries and collect results\n",
    "        all_results = []\n",
    "        \n",
    "        for query_info in all_queries:\n",
    "            results = self._execute_query(\n",
    "                query_text=query_info['query'],\n",
    "                n_results=query_info.get('n_results', default_top_k['code']),\n",
    "                category_filter=query_info.get('category_filter'),\n",
    "                chunk_type_filter=query_info.get('chunk_type_filter'),\n",
    "                source_query=query_info['query']\n",
    "            )\n",
    "            all_results.extend(results)\n",
    "        \n",
    "        # Deduplicate and organize results\n",
    "        organized_results = self._organize_results(all_results, script_json)\n",
    "        \n",
    "        return organized_results\n",
    "    \n",
    "    def _extract_all_queries(self, script_json: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Extract all retrieval queries from the script JSON\n",
    "        \n",
    "        Returns:\n",
    "            List of query dictionaries with metadata\n",
    "        \"\"\"\n",
    "        queries = []\n",
    "        \n",
    "        # Get global context queries\n",
    "        queries.extend(self._get_global_queries(script_json))\n",
    "        \n",
    "        # Get scene-specific queries\n",
    "        for scene in script_json.get('scenes', []):\n",
    "            queries.extend(self._get_scene_queries(scene, script_json))\n",
    "        \n",
    "        return queries\n",
    "    \n",
    "    def _get_global_queries(self, script_json: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Generate queries for global script context\"\"\"\n",
    "        queries = []\n",
    "        \n",
    "        title = script_json.get('title', '')\n",
    "        audience = script_json.get('audience', 'intermediate')\n",
    "        style = script_json.get('style', {})\n",
    "        \n",
    "        # Query for overall animation approach\n",
    "        if title:\n",
    "            queries.append({\n",
    "                'query': f\"Create animation about: {title}. Audience: {audience}\",\n",
    "                'n_results': 3,\n",
    "                'category_filter': None,\n",
    "                'chunk_type_filter': 'example',\n",
    "                'context': 'global'\n",
    "            })\n",
    "        \n",
    "        # Query for style-specific techniques\n",
    "        pacing = style.get('pacing', 'medium')\n",
    "        if pacing in ['slow', 'fast']:\n",
    "            queries.append({\n",
    "                'query': f\"Animation timing and {pacing} pacing techniques\",\n",
    "                'n_results': 2,\n",
    "                'category_filter': 'animation',\n",
    "                'chunk_type_filter': None,\n",
    "                'context': 'global'\n",
    "            })\n",
    "        \n",
    "        return queries\n",
    "    \n",
    "    def _get_scene_queries(self, scene: Dict[str, Any], \n",
    "                          script_json: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Generate queries for a specific scene\"\"\"\n",
    "        queries = []\n",
    "        \n",
    "        scene_id = scene.get('id', 'unknown')\n",
    "        scene_goal = scene.get('goal', '')\n",
    "        \n",
    "        # Query based on scene goal\n",
    "        if scene_goal:\n",
    "            queries.append({\n",
    "                'query': scene_goal,\n",
    "                'n_results': 3,\n",
    "                'category_filter': None,\n",
    "                'chunk_type_filter': None,\n",
    "                'context': f'scene:{scene_id}'\n",
    "            })\n",
    "        \n",
    "        # Process each action in the scene\n",
    "        for action in scene.get('actions', []):\n",
    "            queries.extend(self._get_action_queries(action, scene_id))\n",
    "        \n",
    "        # Query for transition if specified\n",
    "        transition = scene.get('transition_to_next', {})\n",
    "        if transition.get('type'):\n",
    "            queries.append({\n",
    "                'query': f\"{transition['type']} transition animation\",\n",
    "                'n_results': 2,\n",
    "                'category_filter': 'animation',\n",
    "                'chunk_type_filter': 'example',\n",
    "                'context': f'scene:{scene_id}:transition'\n",
    "            })\n",
    "        \n",
    "        return queries\n",
    "    \n",
    "    def _get_action_queries(self, action: Dict[str, Any], \n",
    "                           scene_id: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Generate queries for a specific action\"\"\"\n",
    "        queries = []\n",
    "        \n",
    "        action_id = action.get('id', 'unknown')\n",
    "        retrieval = action.get('retrieval', {})\n",
    "        \n",
    "        # Skip if no retrieval needed\n",
    "        if not retrieval.get('unknown_api_intent', False):\n",
    "            return queries\n",
    "        \n",
    "        # Process exact symbols\n",
    "        exact_symbols = retrieval.get('exact_symbols', [])\n",
    "        for symbol in exact_symbols:\n",
    "            queries.append({\n",
    "                'query': f\"class {symbol} usage and parameters\",\n",
    "                'n_results': 2,\n",
    "                'category_filter': None,\n",
    "                'chunk_type_filter': None,\n",
    "                'context': f'scene:{scene_id}:action:{action_id}'\n",
    "            })\n",
    "        \n",
    "        # Process custom queries\n",
    "        custom_queries = retrieval.get('queries', [])\n",
    "        for query in custom_queries:\n",
    "            queries.append({\n",
    "                'query': query,\n",
    "                'n_results': 3,\n",
    "                'category_filter': None,\n",
    "                'chunk_type_filter': None,\n",
    "                'context': f'scene:{scene_id}:action:{action_id}'\n",
    "            })\n",
    "        \n",
    "        # Process tags to generate targeted queries\n",
    "        tags = retrieval.get('tags', [])\n",
    "        if tags:\n",
    "            # Combine tags into a single query\n",
    "            tag_query = ' '.join(tags)\n",
    "            queries.append({\n",
    "                'query': tag_query,\n",
    "                'n_results': 3,\n",
    "                'category_filter': None,\n",
    "                'chunk_type_filter': None,\n",
    "                'context': f'scene:{scene_id}:action:{action_id}'\n",
    "            })\n",
    "        \n",
    "        # Use code_intent if available\n",
    "        code_intent = action.get('code_intent', '')\n",
    "        if code_intent:\n",
    "            queries.append({\n",
    "                'query': code_intent,\n",
    "                'n_results': 4,\n",
    "                'category_filter': None,\n",
    "                'chunk_type_filter': 'example',\n",
    "                'context': f'scene:{scene_id}:action:{action_id}'\n",
    "            })\n",
    "        \n",
    "        return queries\n",
    "    \n",
    "    def _execute_query(self, query_text: str, n_results: int = 5,\n",
    "                      category_filter: Optional[str] = None,\n",
    "                      chunk_type_filter: Optional[str] = None,\n",
    "                      source_query: str = \"\") -> List[RetrievalResult]:\n",
    "        \"\"\"\n",
    "        Execute a single query against ChromaDB\n",
    "        \n",
    "        Args:\n",
    "            query_text: The search query\n",
    "            n_results: Number of results to return\n",
    "            category_filter: Filter by category (animation, mobject, etc.)\n",
    "            chunk_type_filter: Filter by chunk type (overview, example, parameters)\n",
    "            source_query: Original query for tracking\n",
    "            \n",
    "        Returns:\n",
    "            List of RetrievalResult objects\n",
    "        \"\"\"\n",
    "        # Build where clause\n",
    "        where = {}\n",
    "        if category_filter:\n",
    "            where['category'] = category_filter\n",
    "        if chunk_type_filter:\n",
    "            where['type'] = chunk_type_filter\n",
    "        \n",
    "        where_clause = where if where else None\n",
    "        \n",
    "        try:\n",
    "            # Query ChromaDB\n",
    "            results = self.collection.query(\n",
    "                query_texts=[query_text],\n",
    "                n_results=n_results,\n",
    "                where=where_clause\n",
    "            )\n",
    "            \n",
    "            # Convert to RetrievalResult objects\n",
    "            retrieval_results = []\n",
    "            for i in range(len(results['ids'][0])):\n",
    "                metadata = results['metadatas'][0][i]\n",
    "                retrieval_results.append(RetrievalResult(\n",
    "                    chunk_id=results['ids'][0][i],\n",
    "                    text=results['documents'][0][i],\n",
    "                    distance=results['distances'][0][i],\n",
    "                    class_name=metadata.get('class_name', 'Unknown'),\n",
    "                    qualified_name=metadata.get('qualified_name', 'Unknown'),\n",
    "                    category=metadata.get('category', 'Unknown'),\n",
    "                    chunk_type=metadata.get('type', 'Unknown'),\n",
    "                    url=metadata.get('url', ''),\n",
    "                    source_query=source_query or query_text\n",
    "                ))\n",
    "            \n",
    "            return retrieval_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error executing query '{query_text}': {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _organize_results(self, results: List[RetrievalResult], \n",
    "                         script_json: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Organize and deduplicate results into structured format\n",
    "        \n",
    "        Args:\n",
    "            results: List of all retrieval results\n",
    "            script_json: Original script JSON for context\n",
    "            \n",
    "        Returns:\n",
    "            Organized dictionary with deduplicated results\n",
    "        \"\"\"\n",
    "        # Deduplicate by chunk_id (using set)\n",
    "        unique_results = list(set(results))\n",
    "        \n",
    "        # Sort by distance (relevance)\n",
    "        unique_results.sort(key=lambda x: x.distance)\n",
    "        \n",
    "        # Organize by category\n",
    "        by_category = defaultdict(list)\n",
    "        for result in unique_results:\n",
    "            by_category[result.category].append(result)\n",
    "        \n",
    "        # Organize by chunk type\n",
    "        by_type = defaultdict(list)\n",
    "        for result in unique_results:\n",
    "            by_type[result.chunk_type].append(result)\n",
    "        \n",
    "        # Group by class\n",
    "        by_class = defaultdict(list)\n",
    "        for result in unique_results:\n",
    "            by_class[result.qualified_name].append(result)\n",
    "        \n",
    "        # Build output structure\n",
    "        output = {\n",
    "            'metadata': {\n",
    "                'total_queries': len(set(r.source_query for r in results)),\n",
    "                'total_results': len(results),\n",
    "                'unique_results': len(unique_results),\n",
    "                'script_title': script_json.get('title', 'Untitled'),\n",
    "                'audience': script_json.get('audience', 'intermediate')\n",
    "            },\n",
    "            'top_results': [self._result_to_dict(r) for r in unique_results[:10]],\n",
    "            'by_category': {\n",
    "                cat: [self._result_to_dict(r) for r in results]\n",
    "                for cat, results in by_category.items()\n",
    "            },\n",
    "            'by_type': {\n",
    "                typ: [self._result_to_dict(r) for r in results]\n",
    "                for typ, results in by_type.items()\n",
    "            },\n",
    "            'unique_classes': list(by_class.keys()),\n",
    "            'classes_detail': {\n",
    "                cls: {\n",
    "                    'results': [self._result_to_dict(r) for r in results],\n",
    "                    'chunk_types': list(set(r.chunk_type for r in results))\n",
    "                }\n",
    "                for cls, results in by_class.items()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def _result_to_dict(self, result: RetrievalResult) -> Dict[str, Any]:\n",
    "        \"\"\"Convert RetrievalResult to dictionary\"\"\"\n",
    "        return {\n",
    "            'chunk_id': result.chunk_id,\n",
    "            'text': result.text,\n",
    "            'distance': result.distance,\n",
    "            'class_name': result.class_name,\n",
    "            'qualified_name': result.qualified_name,\n",
    "            'category': result.category,\n",
    "            'chunk_type': result.chunk_type,\n",
    "            'url': result.url,\n",
    "            'source_query': result.source_query\n",
    "        }\n",
    "    \n",
    "    def retrieve_by_symbols(self, symbols: List[str], \n",
    "                           n_results_per_symbol: int = 3) -> Dict[str, List[Dict[str, Any]]]:\n",
    "        \"\"\"\n",
    "        Retrieve documentation for specific symbols/class names\n",
    "        \n",
    "        Args:\n",
    "            symbols: List of class/function names to look up\n",
    "            n_results_per_symbol: Number of results per symbol\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary mapping symbol names to results\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for symbol in symbols:\n",
    "            query_results = self._execute_query(\n",
    "                query_text=f\"class {symbol} methods parameters usage\",\n",
    "                n_results=n_results_per_symbol,\n",
    "                source_query=f\"symbol:{symbol}\"\n",
    "            )\n",
    "            \n",
    "            results[symbol] = [self._result_to_dict(r) for r in query_results]\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_examples_by_category(self, category: str, \n",
    "                                 n_results: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Get code examples for a specific category\n",
    "        \n",
    "        Args:\n",
    "            category: Category to filter by (animation, mobject, etc.)\n",
    "            n_results: Number of examples to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            List of example results\n",
    "        \"\"\"\n",
    "        results = self._execute_query(\n",
    "            query_text=f\"{category} code examples\",\n",
    "            n_results=n_results,\n",
    "            category_filter=category,\n",
    "            chunk_type_filter='example',\n",
    "            source_query=f\"category:{category}\"\n",
    "        )\n",
    "        \n",
    "        return [self._result_to_dict(r) for r in results]\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     \"\"\"Command-line interface for testing queries\"\"\"\n",
    "#     parser = argparse.ArgumentParser(\n",
    "#         description='Retrieve Manim documentation context from ChromaDB based on animation script'\n",
    "#     )\n",
    "#     parser.add_argument('script_json', type=str, \n",
    "#                        help='Path to animation script JSON file')\n",
    "#     parser.add_argument('--db-path', type=str, default='./manim_chromadb',\n",
    "#                        help='Path to ChromaDB storage (default: ./manim_chromadb)')\n",
    "#     parser.add_argument('--collection-name', type=str, default='manim_docs',\n",
    "#                        help='ChromaDB collection name (default: manim_docs)')\n",
    "#     parser.add_argument('--output', type=str, default=None,\n",
    "#                        help='Output file for results (default: print to console)')\n",
    "#     parser.add_argument('--pretty', action='store_true',\n",
    "#                        help='Pretty print JSON output')\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "    \n",
    "#     # Load script JSON\n",
    "#     script_path = Path(args.script_json)\n",
    "#     if not script_path.exists():\n",
    "#         print(f\"ERROR: Script file not found: {args.script_json}\")\n",
    "#         return\n",
    "    \n",
    "#     with open(script_path, 'r') as f:\n",
    "#         script_json = json.load(f)\n",
    "    \n",
    "#     print(f\"Loaded script: {script_json.get('title', 'Untitled')}\")\n",
    "#     print(f\"Scenes: {len(script_json.get('scenes', []))}\")\n",
    "    \n",
    "#     # Initialize retriever\n",
    "#     retriever = ManimContextRetriever(\n",
    "#         db_path=args.db_path,\n",
    "#         collection_name=args.collection_name\n",
    "#     )\n",
    "    \n",
    "#     # Retrieve context\n",
    "#     print(\"\\nRetrieving context from ChromaDB...\")\n",
    "#     results = retriever.retrieve_for_script(script_json)\n",
    "    \n",
    "#     # Output results\n",
    "#     if args.output:\n",
    "#         with open(args.output, 'w') as f:\n",
    "#             json.dump(results, f, indent=2 if args.pretty else None)\n",
    "#         print(f\"\\nResults written to: {args.output}\")\n",
    "#     else:\n",
    "#         if args.pretty:\n",
    "#             print(\"\\n\" + \"=\"*80)\n",
    "#             print(\"RETRIEVAL RESULTS\")\n",
    "#             print(\"=\"*80)\n",
    "#             print(json.dumps(results, indent=2))\n",
    "#         else:\n",
    "#             print(json.dumps(results))\n",
    "    \n",
    "#     # Print summary\n",
    "#     print(\"\\n\" + \"=\"*80)\n",
    "#     print(\"SUMMARY\")\n",
    "#     print(\"=\"*80)\n",
    "#     print(f\"Total queries executed: {results['metadata']['total_queries']}\")\n",
    "#     print(f\"Total results: {results['metadata']['total_results']}\")\n",
    "#     print(f\"Unique results: {results['metadata']['unique_results']}\")\n",
    "#     print(f\"Unique classes found: {len(results['unique_classes'])}\")\n",
    "#     print(f\"\\nClasses: {', '.join(results['unique_classes'][:10])}\")\n",
    "#     if len(results['unique_classes']) > 10:\n",
    "#         print(f\"  ... and {len(results['unique_classes']) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79afae64",
   "metadata": {},
   "source": [
    "### manim_scenes_generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25ca7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parallel Manim Scene Code Generator\n",
    "Reads prompts from directory and generates Python code using Gemini API in parallel threads\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "\n",
    "# Thread-safe printing\n",
    "print_lock = Lock()\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "def thread_safe_print(message: str):\n",
    "    \"\"\"Thread-safe printing function\"\"\"\n",
    "    with print_lock:\n",
    "        print(message)\n",
    "\n",
    "\n",
    "def load_prompt_file(prompt_path: Path) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Load prompt from file\n",
    "    \n",
    "    Args:\n",
    "        prompt_path: Path to prompt text file\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (scene_id, prompt_text)\n",
    "    \"\"\"\n",
    "    with open(prompt_path, 'r', encoding='utf-8') as f:\n",
    "        prompt_text = f.read()\n",
    "    \n",
    "    # Extract scene_id from filename (remove _prompt.txt)\n",
    "    scene_id = prompt_path.stem.replace('_prompt', '')\n",
    "    \n",
    "    return scene_id, prompt_text\n",
    "\n",
    "\n",
    "def load_all_prompts(prompts_dir: str) -> List[Tuple[str, str, Path]]:\n",
    "    \"\"\"\n",
    "    Load all prompt files from directory\n",
    "    \n",
    "    Args:\n",
    "        prompts_dir: Directory containing prompt files\n",
    "        \n",
    "    Returns:\n",
    "        List of tuples (scene_id, prompt_text, prompt_path)\n",
    "    \"\"\"\n",
    "    prompts_path = Path(prompts_dir)\n",
    "    \n",
    "    if not prompts_path.exists():\n",
    "        raise FileNotFoundError(f\"Prompts directory not found: {prompts_dir}\")\n",
    "    \n",
    "    # Find all prompt files\n",
    "    prompt_files = list(prompts_path.glob(\"*_prompt.txt\"))\n",
    "    \n",
    "    if not prompt_files:\n",
    "        raise ValueError(f\"No prompt files found in: {prompts_dir}\")\n",
    "    \n",
    "    # Load metadata if available\n",
    "    metadata_file = prompts_path / \"prompts_metadata.json\"\n",
    "    scene_order = []\n",
    "    \n",
    "    if metadata_file.exists():\n",
    "        with open(metadata_file, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "            scene_order = [s['scene_id'] for s in metadata.get('scenes', [])]\n",
    "    \n",
    "    # Load prompts\n",
    "    prompts = []\n",
    "    for prompt_file in prompt_files:\n",
    "        scene_id, prompt_text = load_prompt_file(prompt_file)\n",
    "        prompts.append((scene_id, prompt_text, prompt_file))\n",
    "    \n",
    "    # Sort by scene order if metadata available\n",
    "    if scene_order:\n",
    "        prompts.sort(key=lambda x: scene_order.index(x[0]) if x[0] in scene_order else 999)\n",
    "    else:\n",
    "        prompts.sort(key=lambda x: x[0])\n",
    "    \n",
    "    return prompts\n",
    "\n",
    "\n",
    "def generate_code_with_gemini(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate code using Gemini API\n",
    "    \n",
    "    Args:\n",
    "        prompt: The complete prompt for code generation\n",
    "        \n",
    "    Returns:\n",
    "        Generated code text\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-3-flash-preview\",\n",
    "        contents=prompt,\n",
    "    )\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "\n",
    "def extract_code_from_response(response_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract Python code from LLM response\n",
    "    Handles cases where code is wrapped in markdown code blocks\n",
    "    \n",
    "    Args:\n",
    "        response_text: Raw response from LLM\n",
    "        \n",
    "    Returns:\n",
    "        Clean Python code\n",
    "    \"\"\"\n",
    "    # Check if response contains markdown code blocks\n",
    "    if \"```python\" in response_text:\n",
    "        # Extract code between ```python and ```\n",
    "        parts = response_text.split(\"```python\")\n",
    "        if len(parts) > 1:\n",
    "            code_part = parts[1].split(\"```\")[0]\n",
    "            return code_part.strip()\n",
    "    \n",
    "    elif \"```\" in response_text:\n",
    "        # Extract code between ``` and ```\n",
    "        parts = response_text.split(\"```\")\n",
    "        if len(parts) >= 3:\n",
    "            return parts[1].strip()\n",
    "    \n",
    "    # If no code blocks, return as is (assume entire response is code)\n",
    "    return response_text.strip()\n",
    "\n",
    "\n",
    "def save_generated_code(scene_id: str, code: str, output_dir: str) -> Path:\n",
    "    \"\"\"\n",
    "    Save generated code to file\n",
    "    \n",
    "    Args:\n",
    "        scene_id: Scene identifier\n",
    "        code: Generated Python code\n",
    "        output_dir: Output directory\n",
    "        \n",
    "    Returns:\n",
    "        Path to saved file\n",
    "    \"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    filename = f\"{scene_id}.py\"\n",
    "    filepath = output_path / filename\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(code)\n",
    "    \n",
    "    return filepath\n",
    "\n",
    "\n",
    "def generate_scene_code(scene_id: str, prompt_text: str, prompt_path: Path,\n",
    "                       output_dir: str,\n",
    "                       max_retries: int = 3) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Generate code for a single scene (thread worker function)\n",
    "    \n",
    "    Args:\n",
    "        scene_id: Scene identifier\n",
    "        prompt_text: The prompt for code generation\n",
    "        prompt_path: Path to prompt file (for reference)\n",
    "        output_dir: Output directory for generated code\n",
    "        max_retries: Maximum retry attempts on failure\n",
    "        \n",
    "    Returns:\n",
    "        Result dictionary with status and details\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'scene_id': scene_id,\n",
    "        'success': False,\n",
    "        'output_file': None,\n",
    "        'error': None,\n",
    "        'attempts': 0,\n",
    "        'code_length': 0\n",
    "    }\n",
    "    \n",
    "    thread_safe_print(f\"[{scene_id}] Starting code generation...\")\n",
    "    \n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        result['attempts'] = attempt\n",
    "        \n",
    "        try:\n",
    "            # Generate code using Gemini\n",
    "            thread_safe_print(f\"[{scene_id}] Attempt {attempt}/{max_retries} - Calling Gemini API...\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            response_text = generate_code_with_gemini(prompt_text)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            thread_safe_print(f\"[{scene_id}] API call completed in {elapsed_time:.2f}s\")\n",
    "            \n",
    "            # Extract code from response\n",
    "            code = extract_code_from_response(response_text)\n",
    "            result['code_length'] = len(code)\n",
    "            \n",
    "            if not code or len(code) < 100:\n",
    "                raise ValueError(f\"Generated code too short ({len(code)} chars)\")\n",
    "            \n",
    "            # Validate code contains required imports\n",
    "            if \"from manim import\" not in code and \"import manim\" not in code:\n",
    "                thread_safe_print(f\"[{scene_id}] WARNING: Code missing manim import, adding...\")\n",
    "                code = \"from manim import *\\n\\n\" + code\n",
    "            \n",
    "            # Save code to file\n",
    "            output_file = save_generated_code(scene_id, code, output_dir)\n",
    "            result['output_file'] = str(output_file)\n",
    "            result['success'] = True\n",
    "            \n",
    "            thread_safe_print(f\"[{scene_id}] ✓ Code generated successfully ({len(code)} chars) -> {output_file}\")\n",
    "            break\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Attempt {attempt} failed: {str(e)}\"\n",
    "            thread_safe_print(f\"[{scene_id}] ✗ {error_msg}\")\n",
    "            result['error'] = error_msg\n",
    "            \n",
    "            if attempt < max_retries:\n",
    "                wait_time = attempt * 2  # Exponential backoff\n",
    "                thread_safe_print(f\"[{scene_id}] Retrying in {wait_time}s...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                thread_safe_print(f\"[{scene_id}] ✗ Failed after {max_retries} attempts\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_all_scenes_parallel(prompts_dir: str, output_dir: str, \n",
    "                                 max_workers: int = 4, max_retries: int = 3) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Generate code for all scenes in parallel using thread pool\n",
    "    \n",
    "    Args:\n",
    "        prompts_dir: Directory containing prompt files\n",
    "        output_dir: Output directory for generated code\n",
    "        max_workers: Maximum number of parallel threads\n",
    "        max_retries: Maximum retry attempts per scene\n",
    "        \n",
    "    Returns:\n",
    "        Summary dictionary with results\n",
    "    \"\"\"\n",
    "    # Load all prompts\n",
    "    print(f\"Loading prompts from: {prompts_dir}\")\n",
    "    prompts = load_all_prompts(prompts_dir)\n",
    "    print(f\"Found {len(prompts)} scenes to generate\\n\")\n",
    "    \n",
    "    # Track results\n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create thread pool and submit tasks\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        future_to_scene = {\n",
    "            executor.submit(\n",
    "                generate_scene_code,\n",
    "                scene_id, prompt_text, prompt_path,\n",
    "                output_dir, max_retries\n",
    "            ): scene_id\n",
    "            for scene_id, prompt_text, prompt_path in prompts\n",
    "        }\n",
    "        \n",
    "        # Process completed tasks\n",
    "        for future in as_completed(future_to_scene):\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Compile summary\n",
    "    successful = [r for r in results if r['success']]\n",
    "    failed = [r for r in results if not r['success']]\n",
    "    \n",
    "    summary = {\n",
    "        'total_scenes': len(prompts),\n",
    "        'successful': len(successful),\n",
    "        'failed': len(failed),\n",
    "        'elapsed_time': elapsed_time,\n",
    "        'results': results,\n",
    "        'output_dir': output_dir\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "\n",
    "def print_summary(summary: Dict[str, any]):\n",
    "    \"\"\"Print generation summary\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CODE GENERATION SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total scenes: {summary['total_scenes']}\")\n",
    "    print(f\"Successful: {summary['successful']}\")\n",
    "    print(f\"Failed: {summary['failed']}\")\n",
    "    print(f\"Total time: {summary['elapsed_time']:.2f}s\")\n",
    "    print(f\"Output directory: {summary['output_dir']}\")\n",
    "    \n",
    "    if summary['successful'] > 0:\n",
    "        print(\"\\n✓ Successful generations:\")\n",
    "        for result in summary['results']:\n",
    "            if result['success']:\n",
    "                print(f\"  - {result['scene_id']}: {result['output_file']} ({result['code_length']} chars)\")\n",
    "    \n",
    "    if summary['failed'] > 0:\n",
    "        print(\"\\n✗ Failed generations:\")\n",
    "        for result in summary['results']:\n",
    "            if not result['success']:\n",
    "                print(f\"  - {result['scene_id']}: {result['error']}\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "def save_summary(summary: Dict[str, any], output_dir: str):\n",
    "    \"\"\"Save generation summary to JSON file\"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    summary_file = output_path / \"generation_summary.json\"\n",
    "    \n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nSummary saved to: {summary_file}\")\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     \"\"\"Command-line interface\"\"\"\n",
    "#     parser = argparse.ArgumentParser(\n",
    "#         description='Generate Manim scene code from prompts using Gemini API in parallel'\n",
    "#     )\n",
    "#     parser.add_argument('prompts_dir', type=str,\n",
    "#                        help='Directory containing prompt files')\n",
    "#     parser.add_argument('--output-dir', type=str, default='./generated_scenes',\n",
    "#                        help='Output directory for generated code (default: ./generated_scenes)')\n",
    "#     parser.add_argument('--max-workers', type=int, default=4,\n",
    "#                        help='Maximum parallel threads (default: 4)')\n",
    "#     parser.add_argument('--max-retries', type=int, default=3,\n",
    "#                        help='Maximum retry attempts per scene (default: 3)')\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "    \n",
    "#     if not api_key:\n",
    "#         print(\"ERROR: GEMINI_KEY not found in environment variables\")\n",
    "#         print(f\"Please set GEMINI_KEY in {args.env_file} file\")\n",
    "#         return 1\n",
    "    \n",
    "#     print(f\"Max workers: {args.max_workers}\")\n",
    "#     print(f\"Max retries: {args.max_retries}\\n\")\n",
    "    \n",
    "#     # Generate all scenes\n",
    "#     try:\n",
    "#         summary = generate_all_scenes_parallel(\n",
    "#             prompts_dir=args.prompts_dir,\n",
    "#             output_dir=args.output_dir,\n",
    "#             max_workers=args.max_workers,\n",
    "#             max_retries=args.max_retries\n",
    "#         )\n",
    "        \n",
    "#         # Print and save summary\n",
    "#         print_summary(summary)\n",
    "#         save_summary(summary, args.output_dir)\n",
    "        \n",
    "#         # Return exit code based on success\n",
    "#         return 0 if summary['failed'] == 0 else 1\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"\\nERROR: {str(e)}\")\n",
    "#         return 1\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     exit(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809c8a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parse_and_generate_prompt.py\n",
    "\"\"\"\n",
    "Manim Scene-by-Scene Prompt Generator\n",
    "Generates optimized prompts for LLM code generation, one per scene for parallel rendering\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import argparse\n",
    "from typing import Dict, List, Any, Optional\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ScenePrompt:\n",
    "    \"\"\"Structured prompt for a single scene\"\"\"\n",
    "    scene_id: str\n",
    "    scene_index: int\n",
    "    prompt_text: str\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "\n",
    "class ManimPromptGenerator:\n",
    "    \"\"\"\n",
    "    Generates scene-specific prompts combining script JSON and context JSON\n",
    "    Each scene gets an independent prompt for parallel code generation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, script_json: Dict[str, Any], context_json: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        Initialize prompt generator\n",
    "        \n",
    "        Args:\n",
    "            script_json: Animation script specification\n",
    "            context_json: Retrieved documentation context from ChromaDB\n",
    "        \"\"\"\n",
    "        self.script = script_json\n",
    "        self.context = context_json\n",
    "        \n",
    "        # Build context lookup structures for efficient access\n",
    "        self.context_by_class = self._build_class_lookup()\n",
    "        self.examples_by_category = self._build_category_lookup()\n",
    "    \n",
    "    def _build_class_lookup(self) -> Dict[str, List[Dict[str, Any]]]:\n",
    "        \"\"\"Build lookup table for context by class name\"\"\"\n",
    "        lookup = defaultdict(list)\n",
    "        \n",
    "        classes_detail = self.context.get('classes_detail', {})\n",
    "        for class_name, details in classes_detail.items():\n",
    "            lookup[class_name] = details.get('results', [])\n",
    "        \n",
    "        return dict(lookup)\n",
    "    \n",
    "    def _build_category_lookup(self) -> Dict[str, List[Dict[str, Any]]]:\n",
    "        \"\"\"Build lookup table for examples by category\"\"\"\n",
    "        lookup = defaultdict(list)\n",
    "        \n",
    "        by_category = self.context.get('by_category', {})\n",
    "        for category, results in by_category.items():\n",
    "            # Filter for examples only\n",
    "            examples = [r for r in results if r.get('chunk_type') == 'example']\n",
    "            lookup[category] = examples\n",
    "        \n",
    "        return dict(lookup)\n",
    "    \n",
    "    def generate_all_prompts(self) -> List[ScenePrompt]:\n",
    "        \"\"\"\n",
    "        Generate prompts for all scenes\n",
    "        \n",
    "        Returns:\n",
    "            List of ScenePrompt objects, one per scene\n",
    "        \"\"\"\n",
    "        prompts = []\n",
    "        scenes = self.script.get('scenes', [])\n",
    "        \n",
    "        for idx, scene in enumerate(scenes):\n",
    "            prompt = self.generate_scene_prompt(scene, idx, len(scenes))\n",
    "            prompts.append(prompt)\n",
    "        \n",
    "        return prompts\n",
    "    \n",
    "    def generate_scene_prompt(self, scene: Dict[str, Any], \n",
    "                             scene_index: int, total_scenes: int) -> ScenePrompt:\n",
    "        \"\"\"\n",
    "        Generate a complete prompt for a single scene\n",
    "        \n",
    "        Args:\n",
    "            scene: Scene specification from script JSON\n",
    "            scene_index: Index of this scene (0-based)\n",
    "            total_scenes: Total number of scenes\n",
    "            \n",
    "        Returns:\n",
    "            ScenePrompt object containing the formatted prompt\n",
    "        \"\"\"\n",
    "        scene_id = scene.get('id', f'scene_{scene_index}')\n",
    "        \n",
    "        # Build prompt sections\n",
    "        sections = [\n",
    "            self._build_header(scene, scene_index, total_scenes),\n",
    "            self._build_global_context(),\n",
    "            self._build_scene_context(scene),\n",
    "            self._build_relevant_documentation(scene),\n",
    "            self._build_code_requirements(scene, scene_index, total_scenes),\n",
    "            self._build_output_format(scene_id),\n",
    "        ]\n",
    "        \n",
    "        prompt_text = \"\\n\\n\".join(sections)\n",
    "        \n",
    "        # Build metadata\n",
    "        metadata = {\n",
    "            'scene_id': scene_id,\n",
    "            'scene_index': scene_index,\n",
    "            'total_scenes': total_scenes,\n",
    "            'duration': scene.get('duration_seconds', 0),\n",
    "            'num_actions': len(scene.get('actions', [])),\n",
    "            'has_transition': bool(scene.get('transition_to_next')),\n",
    "            'transition_type': scene.get('transition_to_next', {}).get('type', 'none')\n",
    "        }\n",
    "        \n",
    "        return ScenePrompt(\n",
    "            scene_id=scene_id,\n",
    "            scene_index=scene_index,\n",
    "            prompt_text=prompt_text,\n",
    "            metadata=metadata\n",
    "        )\n",
    "    \n",
    "    def _build_header(self, scene: Dict[str, Any], \n",
    "                     scene_index: int, total_scenes: int) -> str:\n",
    "        \"\"\"Build the prompt header with context\"\"\"\n",
    "        title = self.script.get('title', 'Untitled Animation')\n",
    "        scene_id = scene.get('id', f'scene_{scene_index}')\n",
    "        \n",
    "        header = f\"\"\"# MANIM SCENE GENERATION REQUEST\n",
    "\n",
    "## Animation Project: {title}\n",
    "**Scene {scene_index + 1} of {total_scenes}** (ID: `{scene_id}`)\n",
    "\n",
    "You are tasked with generating a single, self-contained Manim scene class that will be rendered independently as part of a larger animation project. This scene will be rendered in parallel with other scenes and later composited together.\n",
    "\n",
    "**CRITICAL**: This scene must be completely independent and not rely on any state from previous scenes.\"\"\"\n",
    "        \n",
    "        return header\n",
    "    \n",
    "    def _build_global_context(self) -> str:\n",
    "        \"\"\"Build global context section from script\"\"\"\n",
    "        audience = self.script.get('audience', 'intermediate')\n",
    "        style = self.script.get('style', {})\n",
    "        constraints = self.script.get('constraints', {})\n",
    "        \n",
    "        context = f\"\"\"## Global Project Context\n",
    "\n",
    "### Audience\n",
    "- **Level**: {audience}\n",
    "- **Explanation depth**: {\"detailed explanations\" if audience == \"beginner\" else \"concise\" if audience == \"advanced\" else \"moderate explanations\"}\n",
    "\n",
    "### Visual Style\n",
    "- **Aspect ratio**: {style.get('aspect_ratio', '16:9')}\n",
    "- **Pacing**: {style.get('pacing', 'medium')}\n",
    "- **Tone**: {style.get('tone', 'educational')}\n",
    "\n",
    "### Technical Constraints\n",
    "- **Render quality**: {constraints.get('render_quality', 'medium')}\n",
    "- **Avoid heavy compute**: {constraints.get('avoid_heavy_compute', True)}\n",
    "- **Math typesetting**: {constraints.get('math_typesetting', True)}\"\"\"\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    def _build_scene_context(self, scene: Dict[str, Any]) -> str:\n",
    "        \"\"\"Build scene-specific context\"\"\"\n",
    "        duration = scene.get('duration_seconds', 0)\n",
    "        goal = scene.get('goal', '')\n",
    "        voiceover = scene.get('voiceover', '')\n",
    "        on_screen_text = scene.get('on_screen_text', [])\n",
    "        \n",
    "        context = f\"\"\"## Scene Specification\n",
    "\n",
    "### Scene Goal\n",
    "{goal}\n",
    "\n",
    "### Duration\n",
    "**Target**: {duration} seconds\n",
    "\n",
    "### Voiceover Script\n",
    "```\n",
    "{voiceover}\n",
    "```\n",
    "\n",
    "### On-Screen Text Elements\n",
    "{self._format_list(on_screen_text) if on_screen_text else \"No additional on-screen text\"}\n",
    "\n",
    "### Actions Required\n",
    "The scene must accomplish the following actions in sequence:\n",
    "\"\"\"\n",
    "        \n",
    "        # Add actions\n",
    "        actions = scene.get('actions', [])\n",
    "        for idx, action in enumerate(actions, 1):\n",
    "            action_id = action.get('id', f'action_{idx}')\n",
    "            description = action.get('description', '')\n",
    "            code_intent = action.get('code_intent', '')\n",
    "            \n",
    "            context += f\"\\n**Action {idx}** (ID: `{action_id}`)\\n\"\n",
    "            context += f\"- Description: {description}\\n\"\n",
    "            if code_intent:\n",
    "                context += f\"- Code intent: {code_intent}\\n\"\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    def _build_relevant_documentation(self, scene: Dict[str, Any]) -> str:\n",
    "        \"\"\"Build documentation section with relevant context\"\"\"\n",
    "        doc_section = \"\"\"## Relevant Manim Documentation\n",
    "\n",
    "Below is curated documentation relevant to this scene's requirements. You can use these as reference/context for correct API usage, parameters, and patterns.\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        # Collect all symbols needed for this scene\n",
    "        symbols_used = set()\n",
    "        categories_used = set()\n",
    "        \n",
    "        for action in scene.get('actions', []):\n",
    "            retrieval = action.get('retrieval', {})\n",
    "            exact_symbols = retrieval.get('exact_symbols', [])\n",
    "            symbols_used.update(exact_symbols)\n",
    "            \n",
    "            # Extract categories from tags\n",
    "            tags = retrieval.get('tags', [])\n",
    "            for tag in tags:\n",
    "                if tag in ['animation', 'mobject', 'scene', 'camera', 'utility']:\n",
    "                    categories_used.add(tag)\n",
    "        \n",
    "        # Add documentation for each unique symbol\n",
    "        if symbols_used:\n",
    "            doc_section += \"### Class Documentation\\n\\n\"\n",
    "            \n",
    "            for symbol in sorted(symbols_used):\n",
    "                symbol_docs = self._get_symbol_documentation(symbol)\n",
    "                if symbol_docs:\n",
    "                    doc_section += symbol_docs + \"\\n\\n\"\n",
    "        \n",
    "        # Add relevant examples by category\n",
    "        if categories_used:\n",
    "            doc_section += \"### Relevant Code Examples\\n\\n\"\n",
    "            \n",
    "            for category in sorted(categories_used):\n",
    "                examples = self.examples_by_category.get(category, [])\n",
    "                if examples:\n",
    "                    doc_section += f\"#### {category.capitalize()} Examples\\n\\n\"\n",
    "                    # Include top 2 examples per category\n",
    "                    for example in examples[:2]:\n",
    "                        doc_section += self._format_example(example) + \"\\n\"\n",
    "        \n",
    "        # Add top general results if no specific docs found\n",
    "        if not symbols_used and not categories_used:\n",
    "            doc_section += \"### General Reference\\n\\n\"\n",
    "            top_results = self.context.get('top_results', [])[:3]\n",
    "            for result in top_results:\n",
    "                doc_section += self._format_context_result(result) + \"\\n\"\n",
    "        \n",
    "        return doc_section\n",
    "    \n",
    "    def _get_symbol_documentation(self, symbol: str) -> Optional[str]:\n",
    "        \"\"\"Get documentation for a specific symbol/class\"\"\"\n",
    "        # Try exact match first\n",
    "        for class_name, results in self.context_by_class.items():\n",
    "            if symbol in class_name:\n",
    "                # Find overview chunk\n",
    "                overview = next((r for r in results if r.get('chunk_type') == 'overview'), None)\n",
    "                parameters = next((r for r in results if r.get('chunk_type') == 'parameters'), None)\n",
    "                example = next((r for r in results if r.get('chunk_type') == 'example'), None)\n",
    "                \n",
    "                doc = f\"#### `{class_name}`\\n\\n\"\n",
    "                \n",
    "                if overview:\n",
    "                    doc += f\"{overview['text']}\\n\\n\"\n",
    "                \n",
    "                if parameters:\n",
    "                    doc += \"**Parameters:**\\n```\\n\" + parameters['text'] + \"\\n```\\n\\n\"\n",
    "                \n",
    "                if example:\n",
    "                    doc += \"**Example:**\\n```python\\n\" + example['text'] + \"\\n```\\n\\n\"\n",
    "                \n",
    "                return doc\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _format_example(self, example: Dict[str, Any]) -> str:\n",
    "        \"\"\"Format a code example for display\"\"\"\n",
    "        class_name = example.get('class_name', 'Unknown')\n",
    "        text = example.get('text', '')\n",
    "        \n",
    "        return f\"**{class_name}**\\n```python\\n{text}\\n```\\n\"\n",
    "    \n",
    "    def _format_context_result(self, result: Dict[str, Any]) -> str:\n",
    "        \"\"\"Format a generic context result\"\"\"\n",
    "        qualified_name = result.get('qualified_name', 'Unknown')\n",
    "        text = result.get('text', '')\n",
    "        chunk_type = result.get('chunk_type', 'unknown')\n",
    "        \n",
    "        return f\"**{qualified_name}** ({chunk_type})\\n```\\n{text}\\n```\\n\"\n",
    "    \n",
    "    def _build_code_requirements(self, scene: Dict[str, Any], \n",
    "                                scene_index: int, total_scenes: int) -> str:\n",
    "        \"\"\"Build code generation requirements section\"\"\"\n",
    "        scene_id = scene.get('id', f'scene_{scene_index}')\n",
    "        duration = scene.get('duration_seconds', 0)\n",
    "        transition = scene.get('transition_to_next', {})\n",
    "        \n",
    "        requirements = f\"\"\"## Code Generation Requirements\n",
    "\n",
    "### Class Structure\n",
    "Generate a single Python class that:\n",
    "1. **Class name**: `{self._to_class_name(scene_id)}`\n",
    "2. **Inherits from**: `Scene` (from manim)\n",
    "3. **Single method**: `construct(self)` containing all animation logic\n",
    "\n",
    "### Scene Independence\n",
    "- This scene will be rendered separately and composited later\n",
    "- Do NOT reference any objects or state from other scenes\n",
    "- Initialize all objects within this scene's `construct` method\n",
    "- The scene should be completely self-contained\n",
    "\n",
    "### Timing Requirements\n",
    "- **Target duration**: {duration} seconds\n",
    "- Plan animations to fit within this timeframe\n",
    "- Use appropriate `run_time` parameters for animations\n",
    "- Consider using `self.wait()` for pacing\n",
    "\n",
    "### Output Preparation\"\"\"\n",
    "        \n",
    "        # Add transition requirements\n",
    "        if transition.get('type') and scene_index < total_scenes - 1:\n",
    "            trans_type = transition.get('type')\n",
    "            trans_desc = transition.get('description', '')\n",
    "            \n",
    "            requirements += f\"\"\"\n",
    "\n",
    "### Transition to Next Scene\n",
    "This scene should END with a state that enables a `{trans_type}` transition to the next scene.\n",
    "- **Transition type**: {trans_type}\n",
    "- **Description**: {trans_desc}\n",
    "\n",
    "**Requirements for {trans_type} transition:**\n",
    "\"\"\"\n",
    "            \n",
    "            if trans_type == 'fade':\n",
    "                requirements += \"\"\"- End with objects in their final positions\n",
    "- The compositor will apply a fade effect between scenes\"\"\"\n",
    "            \n",
    "            elif trans_type == 'transform':\n",
    "                requirements += \"\"\"- Export the final state of key objects\n",
    "- Objects should be in positions suitable for morphing to next scene\n",
    "- Use clear naming for objects that will transform\"\"\"\n",
    "            \n",
    "            elif trans_type == 'camera_move':\n",
    "                requirements += \"\"\"- Set camera to final position at end\n",
    "- The next scene will pick up from this camera state\"\"\"\n",
    "            \n",
    "            elif trans_type == 'wipe':\n",
    "                requirements += \"\"\"- End with a clean composition\n",
    "- Objects should be arranged for wipe transition\"\"\"\n",
    "            \n",
    "            else:  # cut or other\n",
    "                requirements += \"\"\"- End with a complete visual state\n",
    "- Ensure clean ending frame\"\"\"\n",
    "        \n",
    "        else:\n",
    "            requirements += \"\"\"\n",
    "\n",
    "### Scene Ending\n",
    "This is the final scene. End with a clean, complete state.\"\"\"\n",
    "        \n",
    "        requirements += \"\"\"\n",
    "\n",
    "### Best Practices\n",
    "1. **Import statements**: Include all necessary imports at the top\n",
    "2. **Comments**: Add clear comments explaining key steps\n",
    "3. **Error handling**: Use safe animations that won't fail during render\n",
    "4. **Performance**: Avoid unnecessary complexity given the constraints\n",
    "5. **Readability**: Use clear variable names and logical structure\"\"\"\n",
    "        \n",
    "        return requirements\n",
    "    \n",
    "    def _build_output_format(self, scene_id: str) -> str:\n",
    "        \"\"\"Build output format instructions\"\"\"\n",
    "        class_name = self._to_class_name(scene_id)\n",
    "        \n",
    "        output = f\"\"\"## Output Format\n",
    "\n",
    "Provide ONLY the complete Python code for the scene class. No explanations before or after.\n",
    "\n",
    "### Required Structure:\n",
    "```python\n",
    "from manim import *\n",
    "\n",
    "class {class_name}(Scene):\n",
    "    def construct(self):\n",
    "        # Your animation code here\n",
    "        pass\n",
    "```\n",
    "\n",
    "### File naming:\n",
    "This code will be saved as: `{scene_id}.py`\n",
    "\n",
    "### Rendering:\n",
    "The scene will be rendered using:\n",
    "```bash\n",
    "manim -qm {scene_id}.py {class_name}\n",
    "```\n",
    "\n",
    "Generate the complete, working Manim scene code now.\"\"\"\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def _to_class_name(self, scene_id: str) -> str:\n",
    "        \"\"\"Convert scene ID to valid Python class name\"\"\"\n",
    "        # Remove special characters and convert to PascalCase\n",
    "        parts = scene_id.replace('-', '_').replace(' ', '_').split('_')\n",
    "        class_name = ''.join(word.capitalize() for word in parts if word)\n",
    "        return class_name + 'Scene'\n",
    "    \n",
    "    def _format_list(self, items: List[str]) -> str:\n",
    "        \"\"\"Format a list of strings as markdown\"\"\"\n",
    "        return '\\n'.join(f\"- {item}\" for item in items)\n",
    "    \n",
    "    def save_prompts(self, prompts: List[ScenePrompt], output_dir: str):\n",
    "        \"\"\"\n",
    "        Save prompts to individual files\n",
    "        \n",
    "        Args:\n",
    "            prompts: List of generated prompts\n",
    "            output_dir: Directory to save prompt files\n",
    "        \"\"\"\n",
    "        output_path = Path(output_dir)\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save each prompt\n",
    "        for prompt in prompts:\n",
    "            filename = f\"{prompt.scene_id}_prompt.txt\"\n",
    "            filepath = output_path / filename\n",
    "            \n",
    "            with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                f.write(prompt.prompt_text)\n",
    "            \n",
    "            print(f\"Saved prompt: {filepath}\")\n",
    "        \n",
    "        # Save metadata summary\n",
    "        metadata_file = output_path / \"prompts_metadata.json\"\n",
    "        metadata = {\n",
    "            'total_prompts': len(prompts),\n",
    "            'scenes': [\n",
    "                {\n",
    "                    'scene_id': p.scene_id,\n",
    "                    'scene_index': p.scene_index,\n",
    "                    'prompt_file': f\"{p.scene_id}_prompt.txt\",\n",
    "                    **p.metadata\n",
    "                }\n",
    "                for p in prompts\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        with open(metadata_file, 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nSaved metadata: {metadata_file}\")\n",
    "        print(f\"Total prompts generated: {len(prompts)}\")\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     \"\"\"Command-line interface\"\"\"\n",
    "#     parser = argparse.ArgumentParser(\n",
    "#         description='Generate scene-specific prompts for Manim code generation'\n",
    "#     )\n",
    "#     parser.add_argument('script_json', type=str,\n",
    "#                        help='Path to animation script JSON file')\n",
    "#     parser.add_argument('context_json', type=str,\n",
    "#                        help='Path to retrieved context JSON file')\n",
    "#     parser.add_argument('--output-dir', type=str, default='./prompts',\n",
    "#                        help='Directory to save generated prompts (default: ./prompts)')\n",
    "#     parser.add_argument('--print-prompts', action='store_true',\n",
    "#                        help='Print prompts to console in addition to saving')\n",
    "#     parser.add_argument('--scene-index', type=int, default=None,\n",
    "#                        help='Generate prompt for specific scene index only (0-based)')\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "    \n",
    "#     # Load input files\n",
    "#     print(\"Loading input files...\")\n",
    "    \n",
    "#     with open(args.script_json, 'r') as f:\n",
    "#         script_json = json.load(f)\n",
    "    \n",
    "#     with open(args.context_json, 'r') as f:\n",
    "#         context_json = json.load(f)\n",
    "    \n",
    "#     print(f\"Script: {script_json.get('title', 'Untitled')}\")\n",
    "#     print(f\"Scenes: {len(script_json.get('scenes', []))}\")\n",
    "#     print(f\"Context entries: {context_json.get('metadata', {}).get('unique_results', 0)}\")\n",
    "    \n",
    "#     # Generate prompts\n",
    "#     print(\"\\nGenerating prompts...\")\n",
    "#     generator = ManimPromptGenerator(script_json, context_json)\n",
    "    \n",
    "#     if args.scene_index is not None:\n",
    "#         # Generate single scene prompt\n",
    "#         scenes = script_json.get('scenes', [])\n",
    "#         if 0 <= args.scene_index < len(scenes):\n",
    "#             scene = scenes[args.scene_index]\n",
    "#             prompt = generator.generate_scene_prompt(\n",
    "#                 scene, args.scene_index, len(scenes)\n",
    "#             )\n",
    "#             prompts = [prompt]\n",
    "#             print(f\"Generated prompt for scene {args.scene_index}\")\n",
    "#         else:\n",
    "#             print(f\"ERROR: Scene index {args.scene_index} out of range (0-{len(scenes)-1})\")\n",
    "#             return\n",
    "#     else:\n",
    "#         # Generate all prompts\n",
    "#         prompts = generator.generate_all_prompts()\n",
    "#         print(f\"Generated {len(prompts)} prompts\")\n",
    "    \n",
    "#     # Save prompts\n",
    "#     generator.save_prompts(prompts, args.output_dir)\n",
    "    \n",
    "#     # Optionally print prompts\n",
    "#     if args.print_prompts:\n",
    "#         print(\"\\n\" + \"=\"*80)\n",
    "#         for prompt in prompts:\n",
    "#             print(f\"\\n{'='*80}\")\n",
    "#             print(f\"PROMPT FOR SCENE: {prompt.scene_id}\")\n",
    "#             print(f\"{'='*80}\\n\")\n",
    "#             print(prompt.prompt_text)\n",
    "#             print(\"\\n\")\n",
    "    \n",
    "#     print(\"\\n✓ Prompt generation complete!\")\n",
    "#     print(f\"Prompts saved to: {args.output_dir}\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c10670",
   "metadata": {},
   "source": [
    "## Now moving on to setup the database of the documentation of manim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c4b5c6",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "%python -m utils.parse_and_store manim_docs_site/docs.manim.community/en/stable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d241814",
   "metadata": {},
   "source": [
    "## Now the database for math problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def3528d",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "%python -m utils.generate_calculus_database\n",
    "%python -m utils.generate_problems_database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef2273b",
   "metadata": {},
   "source": [
    "## Now moving on to the main application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a14d9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
